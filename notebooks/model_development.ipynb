{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mZjH4WcRWDk4",
        "5fVqfwrmWWVX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Sayzek 2024 Datathon Model Eğitimleri***"
      ],
      "metadata": {
        "id": "LOWLpwEQW6LR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **yolov5 Bina Eğitimi**\n"
      ],
      "metadata": {
        "id": "mZjH4WcRWDk4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XbqxeHDV_p0"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"YOLOv5-Custom-Training.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/github/roboflow-ai/yolov5-custom-training-tutorial/blob/main/yolov5-custom-training.ipynb\n",
        "\n",
        "# Custom Training with YOLOv5\n",
        "\n",
        "In this tutorial, we assemble a dataset and train a custom YOLOv5 model to recognize the objects in our dataset. To do so we will take the following steps:\n",
        "\n",
        "* Gather a dataset of images and label our dataset\n",
        "* Export our dataset to YOLOv5\n",
        "* Train YOLOv5 to recognize the objects in our dataset\n",
        "* Evaluate our YOLOv5 model's performance\n",
        "* Run test inference to view our model at work\n",
        "\n",
        "\n",
        "\n",
        "![](https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png)\n",
        "\n",
        "# Step 1: Install Requirements\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "#clone YOLOv5 and\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "# %cd yolov5\n",
        "# %pip install -qr requirements.txt # install dependencies)\n",
        "\n",
        "\"\"\"# Step 2: Assemble Our Dataset\n",
        "\n",
        "In order to train our custom model, we need to assemble a dataset of representative images with bounding box annotations around the objects that we want to detect. And we need our dataset to be in YOLOv5 format.\n",
        "\n",
        "In Roboflow, you can choose between two paths:\n",
        "\n",
        "* Convert an existing dataset to YOLOv5 format. Roboflow supports over [30 formats object detection formats](https://roboflow.com/formats) for conversion.\n",
        "* Upload raw images and annotate them in Roboflow with [Roboflow Annotate](https://docs.roboflow.com/annotate).\n",
        "\n",
        "# Annotate\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/roboflow-annotate.gif)\n",
        "\n",
        "# Version\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/robolfow-preprocessing.png)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"tYWBmPG5o7lpTfzTnKDq\")\n",
        "project = rf.workspace(\"aaaaa-hw2rz\").project(\"sayzek_bina\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov5\")\n",
        "\n",
        "\"\"\"# Step 3: Train Our Custom YOLOv5 model\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
        "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
        "- **cache:** cache images for faster training\n",
        "\"\"\"\n",
        "\n",
        "!python train.py --img 512 --batch 16 --epochs 300 --data {dataset.location}/binadata.yaml --weights yolov5s.pt --cache --patience 65 --workers 4 --hyp /content/yolov5/data/hyps/hyp.scratch-low.yaml\n",
        "\n",
        "\"\"\"# Evaluate Custom YOLOv5 Detector Performance\n",
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile.\n",
        "\n",
        "If you are new to these metrics, the one you want to focus on is `mAP_0.5` - learn more about mean average precision [here](https://blog.roboflow.com/mean-average-precision/).\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir runs\n",
        "\n",
        "\"\"\"#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow.\n",
        "\"\"\"\n",
        "\n",
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 512 --conf 0.1 --source {dataset.location}/test/images\n",
        "\n",
        "#display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")\n",
        "\n",
        "\"\"\"# Conclusion and Next Steps\n",
        "\n",
        "Congratulations! You've trained a custom YOLOv5 model to recognize your custom objects.\n",
        "\n",
        "To improve you model's performance, we recommend first interating on your datasets coverage and quality. See this guide for [model performance improvement](https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results).\n",
        "\n",
        "To deploy your model to an application, see this guide on [exporting your model to deployment destinations](https://github.com/ultralytics/yolov5/issues/251).\n",
        "\n",
        "Once your model is in production, you will want to continually iterate and improve on your dataset and model via [active learning](https://blog.roboflow.com/what-is-active-learning/).\n",
        "\"\"\"\n",
        "\n",
        "#export your model's weights for future use\n",
        "from google.colab import files\n",
        "files.download('./runs/train/exp/weights/best.pt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **yolov5 Silo Eğitimi**"
      ],
      "metadata": {
        "id": "5fVqfwrmWWVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"YOLOv5-Custom-Training.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/github/roboflow-ai/yolov5-custom-training-tutorial/blob/main/yolov5-custom-training.ipynb\n",
        "\n",
        "# Custom Training with YOLOv5\n",
        "\n",
        "In this tutorial, we assemble a dataset and train a custom YOLOv5 model to recognize the objects in our dataset. To do so we will take the following steps:\n",
        "\n",
        "* Gather a dataset of images and label our dataset\n",
        "* Export our dataset to YOLOv5\n",
        "* Train YOLOv5 to recognize the objects in our dataset\n",
        "* Evaluate our YOLOv5 model's performance\n",
        "* Run test inference to view our model at work\n",
        "\n",
        "\n",
        "\n",
        "![](https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png)\n",
        "\n",
        "# Step 1: Install Requirements\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "#clone YOLOv5 and\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "# %cd yolov5\n",
        "# %pip install -qr requirements.txt # install dependencies)\n",
        "\n",
        "\"\"\"# Step 2: Assemble Our Dataset\n",
        "\n",
        "In order to train our custom model, we need to assemble a dataset of representative images with bounding box annotations around the objects that we want to detect. And we need our dataset to be in YOLOv5 format.\n",
        "\n",
        "In Roboflow, you can choose between two paths:\n",
        "\n",
        "* Convert an existing dataset to YOLOv5 format. Roboflow supports over [30 formats object detection formats](https://roboflow.com/formats) for conversion.\n",
        "* Upload raw images and annotate them in Roboflow with [Roboflow Annotate](https://docs.roboflow.com/annotate).\n",
        "\n",
        "# Annotate\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/roboflow-annotate.gif)\n",
        "\n",
        "# Version\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/robolfow-preprocessing.png)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"tYWBmPG5o7lpTfzTnKDq\")\n",
        "project = rf.workspace(\"aaaaa-hw2rz\").project(\"sayzek_silo\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov5\")\n",
        "\n",
        "\"\"\"# Step 3: Train Our Custom YOLOv5 model\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
        "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
        "- **cache:** cache images for faster training\n",
        "\"\"\"\n",
        "\n",
        "!python train.py --img 512 --batch 16 --epochs 300 --data {dataset.location}/silodata.yaml --weights yolov5s.pt --cache --patience 65 --workers 4 --hyp /content/yolov5/data/hyps/hyp.scratch-low.yaml\n",
        "\n",
        "\"\"\"# Evaluate Custom YOLOv5 Detector Performance\n",
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile.\n",
        "\n",
        "If you are new to these metrics, the one you want to focus on is `mAP_0.5` - learn more about mean average precision [here](https://blog.roboflow.com/mean-average-precision/).\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir runs\n",
        "\n",
        "\"\"\"#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow.\n",
        "\"\"\"\n",
        "\n",
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 512 --conf 0.1 --source {dataset.location}/test/images\n",
        "\n",
        "#display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")\n",
        "\n",
        "\"\"\"# Conclusion and Next Steps\n",
        "\n",
        "Congratulations! You've trained a custom YOLOv5 model to recognize your custom objects.\n",
        "\n",
        "To improve you model's performance, we recommend first interating on your datasets coverage and quality. See this guide for [model performance improvement](https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results).\n",
        "\n",
        "To deploy your model to an application, see this guide on [exporting your model to deployment destinations](https://github.com/ultralytics/yolov5/issues/251).\n",
        "\n",
        "Once your model is in production, you will want to continually iterate and improve on your dataset and model via [active learning](https://blog.roboflow.com/what-is-active-learning/).\n",
        "\"\"\"\n",
        "\n",
        "#export your model's weights for future use\n",
        "from google.colab import files\n",
        "files.download('./runs/train/exp/weights/best.pt')\n",
        "\n"
      ],
      "metadata": {
        "id": "A-hG0Ww6WcG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **yolov5 Halısaha Eğitimi**"
      ],
      "metadata": {
        "id": "SKVQmMR4WiZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"YOLOv5-Custom-Training.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/github/roboflow-ai/yolov5-custom-training-tutorial/blob/main/yolov5-custom-training.ipynb\n",
        "\n",
        "# Custom Training with YOLOv5\n",
        "\n",
        "In this tutorial, we assemble a dataset and train a custom YOLOv5 model to recognize the objects in our dataset. To do so we will take the following steps:\n",
        "\n",
        "* Gather a dataset of images and label our dataset\n",
        "* Export our dataset to YOLOv5\n",
        "* Train YOLOv5 to recognize the objects in our dataset\n",
        "* Evaluate our YOLOv5 model's performance\n",
        "* Run test inference to view our model at work\n",
        "\n",
        "\n",
        "\n",
        "![](https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png)\n",
        "\n",
        "# Step 1: Install Requirements\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "#clone YOLOv5 and\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "# %cd yolov5\n",
        "# %pip install -qr requirements.txt # install dependencies)\n",
        "\n",
        "\"\"\"# Step 2: Assemble Our Dataset\n",
        "\n",
        "In order to train our custom model, we need to assemble a dataset of representative images with bounding box annotations around the objects that we want to detect. And we need our dataset to be in YOLOv5 format.\n",
        "\n",
        "In Roboflow, you can choose between two paths:\n",
        "\n",
        "* Convert an existing dataset to YOLOv5 format. Roboflow supports over [30 formats object detection formats](https://roboflow.com/formats) for conversion.\n",
        "* Upload raw images and annotate them in Roboflow with [Roboflow Annotate](https://docs.roboflow.com/annotate).\n",
        "\n",
        "# Annotate\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/roboflow-annotate.gif)\n",
        "\n",
        "# Version\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/robolfow-preprocessing.png)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"tYWBmPG5o7lpTfzTnKDq\")\n",
        "project = rf.workspace(\"aaaaa-hw2rz\").project(\"sayzek_halisaha\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov5\")\n",
        "\n",
        "\"\"\"# Step 3: Train Our Custom YOLOv5 model\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
        "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
        "- **cache:** cache images for faster training\n",
        "\"\"\"\n",
        "\n",
        "!python train.py --img 512 --batch 16 --epochs 300 --data {dataset.location}/halisahadata.yaml --weights yolov5s.pt --cache --patience 65 --workers 4 --hyp /content/yolov5/data/hyps/hyp.scratch-low.yaml\n",
        "\n",
        "\"\"\"# Evaluate Custom YOLOv5 Detector Performance\n",
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile.\n",
        "\n",
        "If you are new to these metrics, the one you want to focus on is `mAP_0.5` - learn more about mean average precision [here](https://blog.roboflow.com/mean-average-precision/).\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir runs\n",
        "\n",
        "\"\"\"#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow.\n",
        "\"\"\"\n",
        "\n",
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 512 --conf 0.1 --source {dataset.location}/test/images\n",
        "\n",
        "#display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")\n",
        "\n",
        "\"\"\"# Conclusion and Next Steps\n",
        "\n",
        "Congratulations! You've trained a custom YOLOv5 model to recognize your custom objects.\n",
        "\n",
        "To improve you model's performance, we recommend first interating on your datasets coverage and quality. See this guide for [model performance improvement](https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results).\n",
        "\n",
        "To deploy your model to an application, see this guide on [exporting your model to deployment destinations](https://github.com/ultralytics/yolov5/issues/251).\n",
        "\n",
        "Once your model is in production, you will want to continually iterate and improve on your dataset and model via [active learning](https://blog.roboflow.com/what-is-active-learning/).\n",
        "\"\"\"\n",
        "\n",
        "#export your model's weights for future use\n",
        "from google.colab import files\n",
        "files.download('./runs/train/exp/weights/best.pt')\n",
        "\n"
      ],
      "metadata": {
        "id": "FL07j0mwWmog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **yolov5 Yol Keşisimi Eğitimi**"
      ],
      "metadata": {
        "id": "nAvB1bn2Wu7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"YOLOv5-Custom-Training.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/github/roboflow-ai/yolov5-custom-training-tutorial/blob/main/yolov5-custom-training.ipynb\n",
        "\n",
        "# Custom Training with YOLOv5\n",
        "\n",
        "In this tutorial, we assemble a dataset and train a custom YOLOv5 model to recognize the objects in our dataset. To do so we will take the following steps:\n",
        "\n",
        "* Gather a dataset of images and label our dataset\n",
        "* Export our dataset to YOLOv5\n",
        "* Train YOLOv5 to recognize the objects in our dataset\n",
        "* Evaluate our YOLOv5 model's performance\n",
        "* Run test inference to view our model at work\n",
        "\n",
        "\n",
        "\n",
        "![](https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png)\n",
        "\n",
        "# Step 1: Install Requirements\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "#clone YOLOv5 and\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "# %cd yolov5\n",
        "# %pip install -qr requirements.txt # install dependencies)\n",
        "\n",
        "\"\"\"# Step 2: Assemble Our Dataset\n",
        "\n",
        "In order to train our custom model, we need to assemble a dataset of representative images with bounding box annotations around the objects that we want to detect. And we need our dataset to be in YOLOv5 format.\n",
        "\n",
        "In Roboflow, you can choose between two paths:\n",
        "\n",
        "* Convert an existing dataset to YOLOv5 format. Roboflow supports over [30 formats object detection formats](https://roboflow.com/formats) for conversion.\n",
        "* Upload raw images and annotate them in Roboflow with [Roboflow Annotate](https://docs.roboflow.com/annotate).\n",
        "\n",
        "# Annotate\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/roboflow-annotate.gif)\n",
        "\n",
        "# Version\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/robolfow-preprocessing.png)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"tYWBmPG5o7lpTfzTnKDq\")\n",
        "project = rf.workspace(\"aaaaa-hw2rz\").project(\"sayzek_yolkesisimi\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov5\")\n",
        "\n",
        "\"\"\"# Step 3: Train Our Custom YOLOv5 model\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
        "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
        "- **cache:** cache images for faster training\n",
        "\"\"\"\n",
        "\n",
        "!python train.py --img 512 --batch 16 --epochs 300 --data {dataset.location}/yoldata.yaml --weights yolov5s.pt --cache --patience 65 --workers 4 --hyp /content/yolov5/data/hyps/hyp.scratch-low.yaml\n",
        "\n",
        "\"\"\"# Evaluate Custom YOLOv5 Detector Performance\n",
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile.\n",
        "\n",
        "If you are new to these metrics, the one you want to focus on is `mAP_0.5` - learn more about mean average precision [here](https://blog.roboflow.com/mean-average-precision/).\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir runs\n",
        "\n",
        "\"\"\"#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow.\n",
        "\"\"\"\n",
        "\n",
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 512 --conf 0.1 --source {dataset.location}/test/images\n",
        "\n",
        "#display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")\n",
        "\n",
        "\"\"\"# Conclusion and Next Steps\n",
        "\n",
        "Congratulations! You've trained a custom YOLOv5 model to recognize your custom objects.\n",
        "\n",
        "To improve you model's performance, we recommend first interating on your datasets coverage and quality. See this guide for [model performance improvement](https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results).\n",
        "\n",
        "To deploy your model to an application, see this guide on [exporting your model to deployment destinations](https://github.com/ultralytics/yolov5/issues/251).\n",
        "\n",
        "Once your model is in production, you will want to continually iterate and improve on your dataset and model via [active learning](https://blog.roboflow.com/what-is-active-learning/).\n",
        "\"\"\"\n",
        "\n",
        "#export your model's weights for future use\n",
        "from google.colab import files\n",
        "files.download('./runs/train/exp/weights/best.pt')\n",
        "\n"
      ],
      "metadata": {
        "id": "Ut0o98ShWyZa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}